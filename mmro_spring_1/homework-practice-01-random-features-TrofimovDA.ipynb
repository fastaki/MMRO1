{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 1. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 17.02.2022\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 03.03.2022 **(за каждый день просрочки снимается 1 балл)**\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 10.03.2022\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу — **10 баллов + 4.3 бонусов.**\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "   * Ноутбук homework-practice-01-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
    "\n",
    "### А также..\n",
    "\n",
    "* Для удобства поиска вопросов, на которые от вас просят ответа, мы пометили их знаком **(?)**\n",
    "* Знак **(!)** означает, что выполнение замечания необходимо для **возможности получения полного балла**\n",
    "* Даем до +0.3 баллов за выдающиеся успехи по субъективному мнению проверяющих. Этот **бонус** не апеллируется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#de3815;font-size:25px;\">\n",
    "Напоминание об оформлении и выполнении ноутбука\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть, не запуская ячейки (кроме редких случаев, когда необходимо намеренно скрыть ненужный output, про такие случаи желательно писать пояснения в тексте). **В противном случае -1 балл**\n",
    "* При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. **В противном случае -1 балл**\n",
    "* В anytask обязательно нужно прикреплять отдельно файл с расширением ipynb (не в архиве, а именно отдельно). Если необходимо отправить еще какие-то файлы, то вынесите их в отдельный архив (если файлов много) и пришлите. **В противном случае -0.5 балла**\n",
    "---\n",
    "* Пишите, пожалуйста, выводы и ответы на вопросы в текстовых ячейках/при помощи print в коде. При их отсутствии мы не можем понять, сделали ли вы задание и понимаете, что происходит, и **поэтому будем снижать баллы**\n",
    "* Если алгоритм не сказано реализовывать явно, его всегда можно импортировать из библиотеки.\n",
    "---\n",
    "* Про графики. _Штрафы будут применяться к каждому результату команды отображения графика (plt.show() и др. аналогичные). Исключением являются графики, генерируемые функциями каких-либо сторонних библиотек, если их нельзя кастомизировать_\n",
    "\n",
    "    * должно быть название (plt.title) графика; **В противном случае &ndash; -0.05 балла**\n",
    "    * на графиках должны быть подписаны оси (plt.xlabel, plt.ylabel); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * должны быть подписаны единицы измерения (если это возможно); **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * все названия должны быть понятны любому человеку, знакомому с терминологией, без заглядывания в код; **В противном случае &ndash; -0.05 балла**\n",
    "    * подписи тиков на осях не должны сливаться как на одной оси, так и между ними; **В противном случае &ndash; -0.025 балла за каждую ось**\n",
    "    * если изображено несколько сущностей на одном холсте (например несколько функций), то необходима поясняющая легенда (plt.legend); **В противном случае &ndash; -0.05 балла**\n",
    "    * все линии на графиках должны быть чётко видны (нет похожих цветов или цветов, сливающихся с фоном); **В противном случае &ndash; -0.05 балла**\n",
    "    * если отображена величина, имеющая очевидный диапазон значений (например, проценты могут быть от 0 до 100), то желательно масштабировать ось на весь диапазон значений (исключением является случай, когда вам необходимо показать малое отличие, которое незаметно в таких масштабах);\n",
    "    * графики должны быть не супер-микро и не супер-макро по размерам, так, чтобы можно было увидеть все, что нужно.\n",
    "    * при необходимости улучшения наглядности графиков, можно пользоваться логарифмической шкалой по осям x/y.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом **Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks)** для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$, где\n",
    "\n",
    "$1/\\sigma^2$ --- **дисперсия распределения.**\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "**Замечание:** обратите внимание на  $i \\neq j$, без этого оценка медианы может быть смещена, а также без этого будут сниматься баллы.\n",
    "\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для игнорирования предупреждений \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напоминание:**\n",
    "    \n",
    "* Все ваши графики должны быть **\"красивыми\"** --- подробнее о том, как их оформлять, можно найти в первом практическом задании. При несоответствии какиму-то из критериев вам могут снять баллы.\n",
    "* Пишите в текстовых ячейках/print в коде ответы на **все вопросы из заданий/просьбы сделать выводы** --- при их отсутствии мы не можем понять, сделали ли вы задание и понимаете, что происходит, и поэтому будем снижать баллы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T17:27:31.242377Z",
     "start_time": "2021-03-05T17:27:30.500833Z"
    },
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВАЖНОЕ ЗАМЕЧАНИЕ:**\n",
    "\n",
    "Датасет по умолчанию хранится в типе 'uint8', вследствие чего при ручном подсчете дисперсии переменные переполняются и вы получаете неадекватные результаты. Бороться с этим можно преобразованием исходных данных к типу 'float'. Еще один хороший вариант &ndash; использовать специализированные функции из библиотек numpy / scipy и, в частности, **scipy.spatial.distance_matrix**.\n",
    "\n",
    "Ниже приводим подтверждающий пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T17:40:50.990485Z",
     "start_time": "2021-03-05T17:40:50.949509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692977.5\n",
      "54218.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "indices = np.random.choice(x_train.shape[0], size=2000)\n",
    "print(np.median(np.sum((x_train[indices[:1000]].astype(float) - x_train[indices[1000:]]).astype(float) ** 2, axis=1)))\n",
    "\n",
    "print(np.median(np.sum((x_train[indices[:1000]] - x_train[indices[1000:]]) ** 2, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "**А) (4 балла)** Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения параметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "\n",
    "**Важно (!)**\n",
    "* Так как мы работаем с линейными моделями, вам необходимо делать нормализацию данных.\n",
    "* Оценка гиперпраметра распределения и построение нового датасета должны быть без питоновских циклов (можно все запрограммировать векторно, используя numpy)\n",
    "\n",
    "**Б) (1 балл)** Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов **не ниже 0.84 с параметрами по умолчанию**, то вы всё сделали правильно.\n",
    "\n",
    "**Подсказка**\n",
    "* Использование метода без PCA и без нормализации признаков перед генерацией весов может дать неожиданные результаты. Сами подумайте, почему так может происходить :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "#https://github.com/Panesher/Machine-Learning/blob/0477cee59d8b26fdd3d36efe8a172e04e3a641ec/ML/HW-8/homework-practice-08-random-features.ipynb\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, pca=PCA(n_components=50), ss=StandardScaler(), classifier=LogisticRegression(),\n",
    "                 cnt_sigma_compute_samples=int(1e6), is_verbose=False):\n",
    "        \"\"\"\n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "\n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        ss, StandardScaler: overparametrized StandardScaler, could be None if don't wanted to be used.\n",
    "\n",
    "        pca, PCA: overparametrized PCA, could be None if don't wanted to be used.\n",
    "\n",
    "        classifier, object: could fit, predict and predict_proba.\n",
    "\n",
    "        cnt_sigma_compute_samples, int: count of samples needed to calculate sigma^2.\n",
    "\n",
    "        is_verbose, bool: if True logs out some progress logs.\n",
    "\n",
    "        Feel free to edit this template for your preferences.\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.pca = pca\n",
    "        self.is_verbose = is_verbose\n",
    "        self.classifier = classifier\n",
    "        self.ss = ss\n",
    "        self.cnt_sigma_compute_samples = cnt_sigma_compute_samples\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "\n",
    "    def _make_random_samples(self, X):\n",
    "        samples = np.random.choice(X.shape[0], (self.cnt_sigma_compute_samples, 2))\n",
    "        samples[samples[:, 0] == samples[:, 1], 1] = (samples[samples[:, 0] == samples[:, 1], 0]\\\n",
    "            + np.random.randint(X.shape[0] - 1, size=samples[samples[:, 0] == samples[:, 1]].shape[0]) + 1) % X.shape[0]\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def _compute_sigma2(self, X):\n",
    "        sigma2_as_vector = np.zeros(self.cnt_sigma_compute_samples)\n",
    "        samples = self._make_random_samples(X)\n",
    "        for k, (i, j) in enumerate(samples):\n",
    "            sigma2_as_vector[k] = ((X[i] - X[j]) ** 2).sum()\n",
    "        return np.median(sigma2_as_vector)\n",
    "\n",
    "    def _generate_w_b(self, X):\n",
    "        sigma2 = self._compute_sigma2(X)\n",
    "        assert sigma2 > 0, 'sigma^2 cant be less or equal 0'\n",
    "        self.w = np.random.normal(0, 1 / np.sqrt(sigma2), (X.shape[1], self.n_features))\n",
    "        self.b = np.random.rand(self.n_features)* 2 * np.pi - np.pi\n",
    "        return self.w, self.b\n",
    "\n",
    "    def _apply_randomized_features(self, X):\n",
    "        assert self.w is not None and self.b is not None, 'w or b cant be None'\n",
    "        return np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "    def log(self, *args):\n",
    "        if self.is_verbose:\n",
    "            print(*args)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.ss is not None:\n",
    "            self.log('Standart scaller fit_transform')\n",
    "            X = self.ss.fit_transform(X)\n",
    "        if self.pca is not None:\n",
    "            self.log('PCA fit_transform')\n",
    "            X = self.pca.fit_transform(X)\n",
    "        self.log('Generating w, b')\n",
    "        self._generate_w_b(X)\n",
    "        self.log('Applying w, b')\n",
    "        X = self._apply_randomized_features(X)\n",
    "        self.log('Fitting classifier')\n",
    "        self.classifier.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def _transform_data(self, X):\n",
    "        \"\"\"\n",
    "        Apply data pipeline\n",
    "        return transformed data\n",
    "        \"\"\"\n",
    "        if self.ss is not None:\n",
    "            self.log('Standart scaller transform')\n",
    "            X = self.ss.transform(X)\n",
    "        if self.pca is not None:\n",
    "            self.log('PCA transform')\n",
    "            X = self.pca.transform(X)\n",
    "        self.log('Applying w, b')\n",
    "        return self._apply_randomized_features(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        X = self._transform_data(X)\n",
    "        self.log('Predicting')\n",
    "        return self.classifier.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        X = self._transform_data(X)\n",
    "        self.log('Predicting')\n",
    "        return self.classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "RFFPipeline()"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline()\n",
    "pipeline.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8552"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_predict = pipeline.predict(x_test)\n",
    "accuracy_score(y_test, test_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "_**(?)** Сравните следующие подходы: **(2.5 балла)**_\n",
    "\n",
    "**Подход со случайными признаками = использование RFFPipeline**\n",
    "\n",
    "* 1) Подход со случайными признаками c типом модели = логистическая регрессия vs обучение линейного SVM на исходных признаках.\n",
    "* 2) Подход со случайными признаками c типом модели = линейный SVM  vs обучение линейного SVM на исходных признаках.\n",
    "* 3) Подход со случайными признаками c типом модели = логистическая регрессия vs обучение ядрового SVM на исходных признаках.\n",
    "* 4) Подход со случайными признаками c типом модели = линейный SVM vs обучение ядрового SVM на исходных признаках.\n",
    "* 5) Подход со случайными признаками c типом модели = логистическая регрессия vs вариант, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost\n",
    "* 6) Подход со случайными признаками c типом модели = линейный SVM vs вариант, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost\n",
    " * 5, 6) **Не забудьте** в этих случаях подобрать число деревьев и длину шага -- здесь, в ноутбуке!\n",
    "\n",
    "_Сделайте выводы: **(0.5 баллов)**_\n",
    "* **(?)** Насколько идея со случайными признаками работает?\n",
    "* **(?)** Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения.\n",
    "\n",
    "**Важные замечания**\n",
    "* Подход по случайными признаками тестируйте в двух вариантах линейной модели. То есть у вас должно получиться всего 6 пар сравнений.\n",
    "* В подходе со случайными признаками в этом задании можно оставиь все параметры, кроме типа модели, по умолчанию.\n",
    "---\n",
    "* Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "* Если вы решили брать подвыборку для какого-то сравнения, то следите за тем, чтобы оба метода обучались на **одинаковом датасете**. Например, сравнивать подход со случайными признаками, обучая его на всем датасете, против ядрового SVM на подвыборке -- некорректно. Тестирование так же должно происходить на одинаковом датасете.\n",
    "* **(!)** Можно в начале этой секции выделить подвыборку и использовать ее для всех экспериментов, если вам это удобно. Необходимо оставить в таком случае хотя бы 10000 объектов. **За меньшее число будут сниматься баллы**\n",
    "---\n",
    "* При сравнении по времени не забывайте смотреть, во сколько потоков реализован алгоритм. Например, сравнивать алгоритм, с параметром n_jobs=-1 (задействовать все возможные потоки) с однопоточным алгоритмом по времени будет некорректно\n",
    "* Если **неуверены**, корректны ли ваши сравнения по времени, поставьте везде n_jobs=1 \n",
    "* Замеряйте время не только обучения, но и обучения + препроцессинга, если он есть (считайте, что формирование признаков в подходе со случайными признаками входит в понятие алгоритма). Так вы сможете более точно проанализировать временные характеристики подходов. \n",
    "---\n",
    "* Переберите хотя бы 10 различных значений количества деревьев (в разумных пределах и с разумным шагом), хотя бы 5 значений параметра learning rate (по логарифмической шкале). Если не знаете, в каких пределах пребирать, то можно найти материалы по соответствующим градиентным бустингам с разбором того, как обычно параметры перебирают.\n",
    "* Перед использованием линейного подхода необходимо нормализовывать признаки (это обычная практика при применении линейных методов, как вы знаете)\n",
    "* Отображать результаты лучше всего будет в виде таблички (pandas DataFrame например), где отображены результаты как  качеств всех алгоритмов, так и времена работы. Можно использовать графическое отображение через bar_plot. Можно также текстом.\n",
    "---\n",
    "* **(!)** Здесь и далее нигде не должно быть сильных просадок по качеству. То есть, если вы получили где-то качество 0.2/0.3/0.4 итд --- это повод задуматься, что где-то у вас есть бага. Во всех экспериментах мы ожидаем качество на тесте не ниже 0.75. **За меньшее качество будут сниматься баллы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#LogReg\n",
    "%%time\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(classifier=LogisticRegression())\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "logreg_ac_score = accuracy_score(y_test, test_predict)\n",
    "logreg_ac_score\n",
    "#logreg_ac_score == 0.8552(почему-то не показывается)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8725"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#LinearSVC\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(classifier=LinearSVC())\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "lin_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "lin_svc_ac_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8537"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#SVC\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(n_features=100, classifier=SVC())\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "svc_ac_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8767"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#SVC lin kernel\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(classifier=SVC(kernel='linear'))\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "lin_ker_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "lin_ker_svc_ac_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from IPython.display import clear_output\n",
    "import optuna"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:21:55,784]\u001B[0m A new study created in memory with name: no-name-5143d425-ec10-48f1-88db-dd901ca266d0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:23:14,999]\u001B[0m Trial 0 finished with value: 0.8838 and parameters: {'subsample': 0.8549161006880356, 'eta': 0.31098445158088645, 'gamma': 2.563468631932663, 'max_depth': 3, 'n_estimators': 35}. Best is trial 0 with value: 0.8838.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:24:45,025]\u001B[0m Trial 1 finished with value: 0.8859 and parameters: {'subsample': 0.25498992880550625, 'eta': 0.08033154520333052, 'gamma': 2.9441264821727997, 'max_depth': 31, 'n_estimators': 41}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:25:10,036]\u001B[0m Trial 2 finished with value: 0.857 and parameters: {'subsample': 0.8527965818536811, 'eta': 0.5168140970345924, 'gamma': 4.865682141039125, 'max_depth': 36, 'n_estimators': 11}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:26:20,753]\u001B[0m Trial 3 finished with value: 0.8804 and parameters: {'subsample': 0.9075360454920638, 'eta': 0.8128059769206536, 'gamma': 0.6637406911913202, 'max_depth': 13, 'n_estimators': 32}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:26:59,117]\u001B[0m Trial 4 finished with value: 0.8672 and parameters: {'subsample': 0.5961358057523072, 'eta': 0.40954268139075495, 'gamma': 0.05916246080436616, 'max_depth': 50, 'n_estimators': 17}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:27:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:27:44,183]\u001B[0m Trial 5 finished with value: 0.8715 and parameters: {'subsample': 0.6045801017583806, 'eta': 0.5396006211693515, 'gamma': 9.001298751495597, 'max_depth': 34, 'n_estimators': 20}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:27:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:28:59,456]\u001B[0m Trial 6 finished with value: 0.8832 and parameters: {'subsample': 0.9457077454088194, 'eta': 0.6258433593684379, 'gamma': 5.332581178409573, 'max_depth': 20, 'n_estimators': 34}. Best is trial 1 with value: 0.8859.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:30:34,065]\u001B[0m Trial 7 finished with value: 0.8867 and parameters: {'subsample': 0.496668337607902, 'eta': 0.8131969298072409, 'gamma': 4.350474298515805, 'max_depth': 28, 'n_estimators': 43}. Best is trial 7 with value: 0.8867.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-10 22:31:49,216]\u001B[0m Trial 8 finished with value: 0.8832 and parameters: {'subsample': 0.6393701326846711, 'eta': 0.991759584477675, 'gamma': 9.626118588115737, 'max_depth': 2, 'n_estimators': 34}. Best is trial 7 with value: 0.8867.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:31:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Boosting\n",
    "def xgb_class(trial):\n",
    "    params = dict()\n",
    "    params.update({'subsample' : trial.suggest_float('subsample', 0.0001, 1)})\n",
    "    params.update({'learning_rate' : trial.suggest_float('eta', 0.0001, 1)})\n",
    "    params.update({'gamma' : trial.suggest_float('gamma', 0, 10)})\n",
    "    params.update({'max_depth' : trial.suggest_int('max_depth', 1, 50)})\n",
    "    model = xgb.XGBClassifier(params, objective='multi:softprob', n_estimators=trial.suggest_int('n_estimators', 1, 50))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    return accuracy_score(y_test, model.predict(x_test))\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(xgb_class, n_trials=15)\n",
    "clear_output()\n",
    "\n",
    "boost_ac_score = study_xgb.best_value\n",
    "print('Best params:', study_xgb.best_params, '\\nResult:', study_xgb.best_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод:\n",
    "1)XGboost показывает лучшие результаты, однако обучается дольше(score не сохранился, но там результат самый высокий, обучалось все около 15 минут)\n",
    "2)В теории можно применять линейный SVM, если попробовать подобрать к нему параметры"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты **(1.5 балла)** над моделью **RFFPipeline**, после которых вы сможете ответить на следующие вопросы **(?)** **(0.5 балла)**:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?\n",
    "\n",
    "**Замечания (!):**\n",
    "* В п.2 необходимо перебрать хотя бы 30 значений признаков по разумной сетке, затрагивающей значения в 50 и в 3000 признаков (или максимальное из того, что позволяет ваш компьтер за разумное время). **За меньшее число признаков и меньшее максимальное значение будут сниматься баллы**\n",
    "* В п.2 используйте логистическую регрессию\n",
    "* В п.2 отобразите качества (accuracy_score) на обучении и на тесте в виде графиков на одном полотне. **За отсутствие будут сниматься баллы**\n",
    "* Везде делайте замеры по времени и результаты включайте в выводы. **За отсутствие будут сниматься баллы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def accuracy_for_pipeline(*args, **kwargs):\n",
    "    set_random_seed(997)\n",
    "    pipeline = RFFPipeline(*args, **kwargs)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    test_predict = pipeline.predict(x_test)\n",
    "    return accuracy_score(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8552"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8606"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8631"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=PCA(100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1116"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=None, ss=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8592"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(ss=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1)Да\n",
    "2)Монотонно возрастает. Как мы видим accuracy выходит на плато (что в общем очевидно ограниченностью)\n",
    "3)Разница есть"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   n_features   score\n0          10  0.5483\n1          56  0.8129\n2         316  0.8481\n3        1778  0.8591\n4       10000  0.8595",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_features</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>0.5483</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>0.8129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>316</td>\n      <td>0.8481</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1778</td>\n      <td>0.8591</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10000</td>\n      <td>0.8595</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "CNT_N_FEATURES = 5\n",
    "\n",
    "df = pd.DataFrame({'n_features': np.logspace(1, 4, CNT_N_FEATURES).astype(int), 'score': [0] * CNT_N_FEATURES})\n",
    "for i, n_features in enumerate(df['n_features']):\n",
    "    df.loc[i, 'score'] = accuracy_for_pipeline(n_features=n_features)\n",
    "clear_output()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "             classifier   score\n0  LogisticRegression()  0.8552\n1           LinearSVC()  0.8725",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>classifier</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression()</td>\n      <td>0.8552</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LinearSVC()</td>\n      <td>0.8725</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'classifier': [LogisticRegression(), LinearSVC()], 'score': [0] * 2})\n",
    "for i, classifier in enumerate(df['classifier']):\n",
    "    df.loc[i, 'score'] = accuracy_for_pipeline(classifier=classifier)\n",
    "clear_output()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://arxiv.org/abs/1610.09072#:~:text=We%20call%20this%20technique%20Orthogonal,to%20speed%20up%20the%20computation). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, **(?)** сделайте выводы.\n",
    "\n",
    "**Замечание:**\n",
    "* Сравнения делайте как по времени, так и по качеству.\n",
    "* Можно сравнивать качество двух методов на разном числе признаков, в таком случае очень полезным будет график зависимости качества от числа признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, **(?)** сравните результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:**\n",
    "* Сравнения делайте как по времени, так и по качеству.\n",
    "* В качестве основной модели можете брать как RFF, так и ORF. А можете и то и другое :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class FunctionRFFP(RFFPipeline):\n",
    "    def __init__(self, function=np.cos, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.function = function\n",
    "\n",
    "    def _apply_randomized_features(self, X):\n",
    "        assert self.w is not None and self.b is not None, 'w or b cant be None'\n",
    "        return self.function(X.dot(self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy_for_model(function, *args, **kwargs):\n",
    "    set_random_seed(997)\n",
    "    pipeline = FunctionRFFP(function, *args, **kwargs)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    test_predict = pipeline.predict(x_test)\n",
    "    clear_output()\n",
    "    return accuracy_score(y_test, test_predict)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1306"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('exp:', accuracy_for_model(np.exp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign: 0.8293\n"
     ]
    }
   ],
   "source": [
    "#np.sign\n",
    "print('sign:', accuracy_for_model(np.sign))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU: 0.8238\n"
     ]
    }
   ],
   "source": [
    "#relu\n",
    "print('ReLU:', accuracy_for_model(relu))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost over random PCA: 0.8507\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('XGBoost over random PCA:', accuracy_for_model(np.cos, n_features=100, classifier=xgb.XGBClassifier(\n",
    "                                                     objective='multi:softprob', max_depth=33, n_estimators=20)))\n",
    "#XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC over random PCA: 0.8278\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC over random PCA:', accuracy_for_model(np.cos, n_features=100, classifier=LinearSVC()))\n",
    "#LinearSVC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost показывает лучшее качество\n",
    "Если данные сильно рандомизированы + постоянное распрередление, то XGboost будет показывать лучшие результаты"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}